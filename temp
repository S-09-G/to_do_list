# ================================================================
# SAMSUNG USER CLUSTERING - CONFIGURATION
# ================================================================
# 
# This system supports:
# 1. PRIMARY FILE: Pre-cleaned user-genre matrix (one row per user)
# 2. SECONDARY FILES: Additional data joined via DUID/GUID
# ================================================================

# ----------------------------------------------------------------
# PATHS
# ----------------------------------------------------------------
paths:
  processed_data: "data/processed/"
  models: "models/"
  reports: "reports/"
  logs: "logs/"

# ----------------------------------------------------------------
# DATA SOURCES
# ----------------------------------------------------------------
data_sources:
  # PRIMARY: Your cleaned user-genre matrix
  # - One row per unique DUID-GUID combination
  # - Columns are genre scores (already pivoted)
  primary:
    path: "data/raw/user_genre_matrix.csv"
    user_id_column: "GUID"           # Column containing user identifier
    device_id_column: "DUID"         # Column containing device identifier (optional)
    # Which columns are features (genres) for clustering?
    # Options: "auto" (detect numeric columns), or list specific columns
    feature_columns: "auto"
    # Columns to EXCLUDE from features (even if numeric)
    exclude_columns: []
    # Example: exclude_columns: ["age", "income", "some_id"]

  # SECONDARY: Additional files to join with primary
  # Each file must have a join key matching primary file
  secondary:
    # Demographics data
    - name: "demographics"
      path: "data/raw/user_demographics.csv"
      enabled: false                  # Set to true when you have this file
      join_key: "GUID"               # Column to join on
      columns_to_use:                # Which columns to include
        - "age_group"
        - "region"
      # How to use these columns for clustering?
      # Options: "feature" (use as clustering feature), "metadata" (keep but don't cluster on)
      usage: "feature"
      # For categorical columns, how to encode?
      # Options: "onehot", "label", "none"
      encoding: "onehot"

    # Device information
    - name: "device_info"
      path: "data/raw/device_info.csv"
      enabled: false
      join_key: "DUID"
      columns_to_use:
        - "device_type"
        - "os_version"
      usage: "metadata"              # Won't be used for clustering, just kept for analysis
      encoding: "none"

    # Add more secondary files as needed
    # - name: "viewing_history"
    #   path: "data/raw/viewing_history.csv"
    #   enabled: false
    #   join_key: "GUID"
    #   columns_to_use: ["total_watch_time", "avg_session_length"]
    #   usage: "feature"
    #   encoding: "none"

# ----------------------------------------------------------------
# FEATURE SELECTION
# ----------------------------------------------------------------
feature_selection:
  # Mode: "all", "include", "exclude"
  mode: "all"
  
  # If mode is "include", only use these features
  include_features: []
  # Example: ["Drama", "Comedy", "Action", "Thriller"]
  
  # If mode is "exclude", remove these features
  exclude_features: []
  # Example: ["Unknown_Genre", "Test_Genre"]
  
  # Remove features with very low variance
  min_variance: 0.0
  
  # Remove highly correlated features (optional)
  max_correlation: 1.0

# ----------------------------------------------------------------
# PREPROCESSING
# ----------------------------------------------------------------
preprocessing:
  # Normalization method
  # Options: "none", "minmax", "standard", "tfidf", "log_tfidf", "row_normalize", "balanced"
  normalization: "balanced"
  
  # Dimensionality reduction
  dimensionality_reduction:
    enabled: true
    method: "svd"                    # Options: "svd", "pca"
    n_components: 50

# ----------------------------------------------------------------
# CLUSTERING ALGORITHMS
# ----------------------------------------------------------------
clustering:
  random_state: 42
  
  k_range:
    min: 3
    max: 20
  
  algorithms:
    - name: "minibatch_kmeans"
      enabled: true
      display_name: "MiniBatch K-Means"
      parameters:
        batch_size: 1024
        n_init: 10
        max_iter: 300

    - name: "gmm"
      enabled: true
      display_name: "Gaussian Mixture Model"
      parameters:
        covariance_type: "full"
        n_init: 5
        max_iter: 200

    - name: "birch"
      enabled: true
      display_name: "BIRCH"
      parameters:
        threshold: 0.1
        branching_factor: 50

# ----------------------------------------------------------------
# EVALUATION
# ----------------------------------------------------------------
evaluation:
  metrics:
    - name: "silhouette"
      enabled: true
      higher_is_better: true
    - name: "calinski_harabasz"
      enabled: true
      higher_is_better: true
    - name: "davies_bouldin"
      enabled: true
      higher_is_better: false

# ----------------------------------------------------------------
# OUTPUT
# ----------------------------------------------------------------
output:
  save_intermediate: true
  save_models: true
  generate_reports: true

# ----------------------------------------------------------------
# LOGGING
# ----------------------------------------------------------------
logging:
  level: "INFO"
  log_to_file: true
  log_filename: "pipeline.log"