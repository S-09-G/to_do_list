import pandas as pd
from pathlib import Path

# =========================
# Paths
# =========================
DATA_DIR = Path("data")
PROCESSED_DIR = DATA_DIR / "processed"

INPUT_FILE = PROCESSED_DIR / "cleaned_data.csv"
OUTPUT_FILE = PROCESSED_DIR / "user_genre_matrix.csv"

# =========================
# Load cleaned data
# =========================
print("Loading cleaned data...")
df = pd.read_csv(INPUT_FILE)

print(f"Input data shape: {df.shape}")
print(f"Unique users (guid): {df['guid'].nunique()}")
print(f"Unique genres: {df['content_genre'].nunique()}")

# =========================
# Create user-genre matrix
# =========================
print("\nCreating user-genre matrix...")

user_genre_matrix = df.pivot_table(
    index="guid",
    columns="content_genre",
    values="score",
    aggfunc="sum",      # Sum scores per user per genre
    fill_value=0       # Missing combinations become 0
)

# =========================
# Basic sanity checks
# =========================
print("User-genre matrix created.")
print(f"Matrix shape: {user_genre_matrix.shape}")

total_cells = user_genre_matrix.shape[0] * user_genre_matrix.shape[1]
zero_cells = (user_genre_matrix == 0).sum().sum()
density = 1 - (zero_cells / total_cells)

print(f"Matrix density: {density:.4f}")
print("\nSample rows:")
print(user_genre_matrix.head())

# =========================
# Save matrix
# =========================
user_genre_matrix.to_csv(OUTPUT_FILE)
print(f"\nUser-genre matrix saved to: {OUTPUT_FILE}")








import pandas as pd
import numpy as np
from pathlib import Path

# =========================
# Paths
# =========================
DATA_DIR = Path("data")
PROCESSED_DIR = DATA_DIR / "processed"

INPUT_FILE = PROCESSED_DIR / "user_genre_matrix.csv"
OUTPUT_FILE = PROCESSED_DIR / "user_genre_matrix_normalized.csv"

# =========================
# Load user-genre matrix
# =========================
print("Loading user-genre matrix...")
df = pd.read_csv(INPUT_FILE, index_col=0)

print(f"Matrix shape: {df.shape}")

# =========================
# L2 Normalization (row-wise)
# =========================
print("Applying L2 normalization per user...")

# Compute L2 norm for each user
l2_norm = np.sqrt((df ** 2).sum(axis=1))

# Avoid division by zero
df_normalized = df.div(l2_norm.replace(0, 1), axis=0)

# =========================
# Sanity checks
# =========================
norm_check = np.sqrt((df_normalized ** 2).sum(axis=1))

print("\nL2 norm statistics (should be ~1.0):")
print(norm_check.describe())

print("\nSample normalized rows:")
print(df_normalized.head())

# =========================
# Save normalized matrix
# =========================
df_normalized.to_csv(OUTPUT_FILE)
print(f"\nNormalized matrix saved to: {OUTPUT_FILE}")









import pandas as pd
from pathlib import Path

# =========================
# Paths
# =========================
DATA_DIR = Path("data")
PROCESSED_DIR = DATA_DIR / "processed"

INPUT_FILE = PROCESSED_DIR / "user_genre_matrix_normalized.csv"
OUTPUT_FILE = PROCESSED_DIR / "user_genre_matrix_filtered.csv"

MIN_GENRES = 3  # minimum non-zero genres per user

# =========================
# Load normalized matrix
# =========================
print("Loading normalized user-genre matrix...")
df = pd.read_csv(INPUT_FILE, index_col=0)

print(f"Initial number of users: {df.shape[0]}")

# =========================
# Count non-zero genres per user
# =========================
non_zero_counts = (df > 0).sum(axis=1)

# =========================
# Filter users
# =========================
df_filtered = df[non_zero_counts >= MIN_GENRES]

print(f"Users after filtering: {df_filtered.shape[0]}")
print(f"Users removed: {df.shape[0] - df_filtered.shape[0]}")

# =========================
# Save filtered matrix
# =========================
df_filtered.to_csv(OUTPUT_FILE)
print(f"\nFiltered matrix saved to: {OUTPUT_FILE}")














import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# =========================
# Paths
# =========================
DATA_DIR = Path("data")
PROCESSED_DIR = DATA_DIR / "processed"

INPUT_FILE = PROCESSED_DIR / "user_genre_matrix_filtered.csv"

# =========================
# Load data
# =========================
print("Loading filtered user-genre matrix...")
X = pd.read_csv(INPUT_FILE, index_col=0)

print(f"Data shape for clustering: {X.shape}")

# =========================
# Range of K
# =========================
k_values = range(2, 16)

inertias = []
silhouette_scores = []

# =========================
# Run KMeans for each K
# =========================
for k in k_values:
    print(f"Running KMeans for K={k}...")
    kmeans = KMeans(
        n_clusters=k,
        random_state=42,
        n_init=10
    )
    labels = kmeans.fit_predict(X)

    inertias.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(X, labels))

# =========================
# Plot Elbow curve
# =========================
plt.figure()
plt.plot(k_values, inertias, marker='o')
plt.xlabel("Number of clusters (K)")
plt.ylabel("Inertia")
plt.title("Elbow Method")
plt.show()

# =========================
# Plot Silhouette scores
# =========================
plt.figure()
plt.plot(k_values, silhouette_scores, marker='o')
plt.xlabel("Number of clusters (K)")
plt.ylabel("Silhouette Score")
plt.title("Silhouette Score vs K")
plt.show()

# =========================
# Print results
# =========================
print("\nK | Inertia | Silhouette Score")
print("-" * 35)
for k, inertia, sil in zip(k_values, inertias, silhouette_scores):
    print(f"{k:2d} | {inertia:.2f} | {sil:.4f}")